{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Uncertainty Values from Reward Samples!\n",
    "\n",
    "##### In this notebook, we want to demonstrate through the process of determining uncertainty values using reward samples. Uncertainty values are crucial for understanding the variability or confidence in the data we observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import balanced_entropy, epistemic_uncertainty, aleatoric_uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with Our Reward Samples\n",
    "\n",
    "##### Let's assume that we have a set of reward samples, specifically the MC-dropout samples of R1 - R2. These samples will be our starting point for calculating uncertainty. We'll explain what R1 and R2 represent and how we can use them to gain insights into the uncertainty of our rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_gap_samples = torch.tensor(\n",
    "    [[-0.5071,  0.3939,  0.6309,  0.5251,  1.2876,  1.1699,  0.5775,  1.1834,\n",
    "       0.1770,  0.1188, -0.5556,  0.1510,  1.7552,  1.0578,  0.8473,  0.0886,\n",
    "       1.3317,  1.1074, -0.2550,  0.0272,  0.9689,  0.8330,  0.5621,  0.2605,\n",
    "      -0.0145]]) # we use 25 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Entropy\n",
    "\n",
    "#### As highlighted in the paper, we compute the Balanced Entropy under the conditions defined by a sigmoid regime. Consequently, our Balanced Entropy is derived by employing the formula outlined below:\n",
    "\n",
    "$$U_{\\text{BalEnt}}\\left(\\mathbf{P}\\right) :=\n",
    "\\frac{\\mathbb{E} P_{y_c\\succ y_r}h\\left( P_{y_c\\succ y_r}^+ \\right) + \\mathbb{E} P_{y_c\\prec y_r}h\\left( P_{y_c\\prec y_r}^+ \\right) + H\\left(\\mathbb{E}\\mathbf{P}\\right)}{H\\left(\\mathbb{E}\\mathbf{P}\\right) +\\log 2 }$$\n",
    "\n",
    "#### To accomplish this, we require the sample mean and standard deviation for the R1-R2 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = torch.mean(reward_gap_samples, dim=1)\n",
    "sample_std = torch.std(reward_gap_samples, dim=1)\n",
    "sample_mean, sample_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsequently, by applying the Trapezoidal rule, we concluded the calculation of Balanced Entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0047])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_entropy(sample_mean, sample_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epistemic Uncertainty and Aleatoric Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epistemic Uncertainty and Aleatoric Uncertainty can be directly calculated using logits. Therefore, we first apply a Sigmoid transform to compute the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.nn.functional.logsigmoid(reward_gap_samples.to(torch.float32))\n",
    "logits = torch.log(torch.stack([torch.exp(logits), 1.-torch.exp(logits)+1e-128], dim=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epistemic Uncertainty\n",
    "\n",
    "#### Epistemic Uncertainty is expressed by the following equation:\n",
    "\n",
    "$$U_{\\text{Epistemic}}\\left(\\mathbf{P}\\right):=H\\left(\\mathbb{E}\\mathbf{P}\\right)+\\mathbb{E}\\left(\\sum_{i \\in I}P_i\\log P_i \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0374])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epistemic_uncertainty(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aleatoric Uncertainty\n",
    "\n",
    "#### Aleatoric Uncertainty is expressed by the following equation:\n",
    "\n",
    "$$U_{\\text{Aleatoric}}\\left(\\mathbf{P}\\right):=-\\mathbb{E}\\left(\\sum_{i \\in I}P_i\\log P_i \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6245])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aleatoric_uncertainty(logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_rm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
